{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pytz\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_values(timestamp, timezone='America/New_York', \n",
    "                    map_2_hrs={str(2*i+k): value for k in range(2) for (i, value) in enumerate(range(12))}):\n",
    "    \n",
    "    dt = datetime.datetime.utcfromtimestamp(timestamp)\n",
    "    dt = pytz.UTC.localize(dt)\n",
    "    dt = dt.astimezone(pytz.timezone(timezone))\n",
    "    hour_of_the_day = dt.hour\n",
    "    day_of_the_week = dt.weekday()\n",
    "    week_of_the_year = dt.isocalendar()[1]\n",
    "    \n",
    "    # Get the 2 hour group id\n",
    "    # dt.hour = 0 and dt.hour = 1 gets mapped to hr_id = 0\n",
    "    # dt.hour = 2 and dt.hour = 3 gets mapped to hr_id = 1\n",
    "    #.\n",
    "    #.\n",
    "    # dt.hour = 22 and dt.hour = 23 gets mapped to hr_id = 11\n",
    "    hr_id = map_2_hrs[str(hour_of_the_day)]\n",
    "    \n",
    "    # Get combination of 2 hour id, day of the week and week of the year to enable groupby later\n",
    "    # This acts as a unique key for a 2-hr window\n",
    "    day_id = str(hr_id)+'-'+str(day_of_the_week)+'-'+str(week_of_the_year)\n",
    "    \n",
    "    return dict(hour_of_the_day=hour_of_the_day,\n",
    "                day_of_the_week=day_of_the_week,\n",
    "                week_of_the_year=week_of_the_year,\n",
    "                day_id=day_id,\n",
    "                hr_id=hr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameter values are evaluated when the function definition is executed.\n",
    "# This means that the expression is evaluated once, when the function is defined, \n",
    "# and that that same ``pre-computed'' value is used for each call. \n",
    "\n",
    "def get_spl_frame_vector_old(spl_vector, spl_iterable=[4*k for k in range(20)],\n",
    "                             frame_keys=['frame_'+ str(i) for i in range(20)]):\n",
    "    \n",
    "    # From list of 80 values in spl_vector, get 20 values for 20 embedding frames by averaging 4 values\n",
    "    # Calculate the min and max of resulting 20 values to make calculation of min and max spl over 2 hr period easier\n",
    "    spl_frames = [0.25*sum([spl_vector[i+k] for k in range(4)]) for i in spl_iterable]\n",
    "    return dict({frame_keys[i]: value for (i, value) in enumerate(spl_frames)},\n",
    "                max_frame=max(spl_frames),\n",
    "                min_frame=min(spl_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_loudness_with_scaling(df):\n",
    "    res = df.groupby(['day_id']).agg({'min_frame': np.min, 'max_frame': np.max}).reset_index()\n",
    "    final = pd.merge(df, res, on='day_id', how='outer', suffixes=('_emb', '_2_hr'))\n",
    "\n",
    "    # Get relative loudness of each frame using the min_frame_2_hr and max_frame_2_hr calculated above\n",
    "    for key in frame_keys:\n",
    "        final[key+'_rel_loudness'] = (final[key] - final['min_frame_2_hr'])/(final['max_frame_2_hr'] - final['min_frame_2_hr'])\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a string: spl_frames = ''.join(','.join(str(0.25*sum([spl_vector[i+k] for k in range(4)])) for i in spl_iterable))\n",
    "def get_spl_frame_vector(spl_vector, spl_iterable=[4*k for k in range(20)]):\n",
    "    \n",
    "    spl_frames = [0.25*sum([spl_vector[i+k] for k in range(4)]) for i in spl_iterable]\n",
    "    return dict({'spl_frames': spl_frames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prob_sum(d, elements, count):\n",
    "    prob_sum = [d[i]/count.sum() for i in elements]\n",
    "    print('Sum of probs: ', np.array(prob_sum).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2_hr_prob_dict(row):\n",
    "    d = {}\n",
    "    spl_frames_2_hr = np.array(row['spl_frames'])\n",
    "    unq, unq_indices = np.unique(spl_frames_2_hr, return_index=True)\n",
    "    total_frames = len(spl_frames_2_hr)\n",
    "    ranked_spl = rankdata(spl_frames_2_hr, method='min')\n",
    "    d = {spl_frames_2_hr[i]: ranked_spl[i]/total_frames for i in unq_indices}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_prob(row):\n",
    "    prob_dict = row['prob_dict_2_hr']\n",
    "    lst = [prob_dict[i] for i in row['spl_frames_emb']]\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_test(df):\n",
    "    print('Dataframe head:')\n",
    "    print(df.head())\n",
    "    print('---------------')\n",
    "    print('Example of unique probability values in the probability distribution over 2 hr window:')\n",
    "    print(np.unique(df.iloc[0, ['prob_spl_2_hr']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_loudness_probs(feats_path, indices_path):\n",
    "\n",
    "    indices = h5py.File(indices_path)\n",
    "    blob = h5py.File(feats_path)\n",
    "\n",
    "    # Get the timestamp from the feature file\n",
    "    ts = blob['openl3']['timestamp']\n",
    "\n",
    "    # Not used as of now\n",
    "    feats = blob['openl3']['openl3']\n",
    "\n",
    "    # Get the spl_vector from the indices file\n",
    "    spl_vecs = indices['recording_index']['spl_vector']\n",
    "\n",
    "    assert feats.shape[0] == ts.shape[0] == spl_vecs.shape[0]\n",
    "\n",
    "    # Get the spl avg value of 4 consecutive values from spl_vector\n",
    "    spl_arr = np.apply_along_axis(get_spl_frame_vector, 1, spl_vecs)\n",
    "\n",
    "    # Apply get_time_values() to each element of the timestamp array \n",
    "    dt_vectorize = np.vectorize(get_time_values)\n",
    "    t_arr = dt_vectorize(ts)\n",
    "\n",
    "    # Convert the dicts obtained above into dataframe and combine them to make aggregation easier\n",
    "    t_df = pd.DataFrame(list(t_arr))\n",
    "    spl_df = pd.DataFrame(list(spl_arr)) \n",
    "    df = pd.concat([t_df, spl_df], axis=1)\n",
    "    \n",
    "    # Round off the SPL values to 2 decimal places to increase the probability of \n",
    "    df['spl_frames'] = df['spl_frames'].apply(lambda x: list(np.around(np.array(x), decimals=2)))\n",
    "    \n",
    "    # Group by 2-hour window\n",
    "    res = df.groupby(['day_id'], as_index = False).agg({'spl_frames': 'sum'}).reset_index() \n",
    "    \n",
    "    # Form a dictionary with spl values mapped to its probability in 2-hour window\n",
    "    res['prob_dict_2_hr'] = res.apply(get_2_hr_prob_dict, axis = 1)\n",
    "    \n",
    "    final = pd.merge(df, res, on='day_id', how='outer', suffixes=('_emb', '_2_hr'))\n",
    "    \n",
    "    # From the 2-hr dictionary, get the probability of the 20 embedding frames corresponding to one entry in blob\n",
    "    final['prob_spl_frames'] = final.apply(get_frame_prob, axis = 1)\n",
    "     \n",
    "    return final['prob_spl_frames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_path = '/beegfs/work/sonyc/features/openl3/2017/sonycnode-b827ebefb215.sonyc_features_openl3.h5'\n",
    "indices_path = '/beegfs/work/sonyc/indices/2017/'+ os.path.basename(feats_path).replace('features_openl3', 'recording_index')\n",
    "\n",
    "prob_spl_frames = get_rel_loudness_probs(feats_path, indices_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1701492537313433, 0.5783582089552238, 0.14029850746268657, 0.2208955223880597, 0.3, 0.3604477611940298, 0.32686567164179103, 0.467910447761194, 0.6701492537313433, 0.655223880597015, 0.4701492537313433, 0.5365671641791044, 0.4141791044776119, 0.655223880597015, 0.7141791044776119, 0.38731343283582087, 0.25970149253731345, 0.367910447761194, 0.3246268656716418, 0.15597014925373134]\n"
     ]
    }
   ],
   "source": [
    "print(prob_spl_frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
