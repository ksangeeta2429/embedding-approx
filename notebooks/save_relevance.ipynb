{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sampling_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_h5(scores, output_path):\n",
    "    \n",
    "    if os.path.isfile(output_path):\n",
    "        print(\"{} already exists. Deleting.\".format(output_path))\n",
    "        os.remove(output_path)\n",
    "        \n",
    "    num_embeddings = 20\n",
    "    with h5py.File(output_path) as h5:\n",
    "        d = h5.create_dataset('recording_index',\n",
    "                              (len(scores),),\n",
    "                              dtype=[('relevance_2hr_vector', 'f4', (num_embeddings,))],)\n",
    "            \n",
    "        for idx, score_vec in enumerate(scores):\n",
    "            d[idx, 'relevance_2hr_vector'] = tuple(score_vec)\n",
    "            \n",
    "        h5.close()\n",
    "        \n",
    "    print('Completed writing to {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevance_scores_files(feats_dir, indices_dir, output_dir):\n",
    "    \n",
    "    for file in os.listdir(feats_dir)[0:2]:\n",
    "        feats_path = os.path.join(feats_dir, file)\n",
    "        indices_path = os.path.join(indices_dir, os.path.basename(file).replace('features_openl3', 'recording_index'))\n",
    "        output_path = os.path.join(output_dir, os.path.basename(file).replace('features_openl3', 'relevance_2hr'))\n",
    "        \n",
    "        indices = h5py.File(indices_path)\n",
    "        spl_vecs = indices['recording_index']['spl_vector']\n",
    "\n",
    "        blob = h5py.File(feats_path)\n",
    "        ts = blob['openl3']['timestamp']\n",
    "        \n",
    "        if ts.shape[0] > 0:\n",
    "            scores = get_relevance_scores(ts, spl_vecs)\n",
    "            write_to_h5(scores, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/beegfs/sk7898/sonyc/relevance/2017/sonycnode-b827ebb40450.sonyc_relevance_2hr.h5 already exists. Deleting.\n",
      "Completed writing to /beegfs/sk7898/sonyc/relevance/2017/sonycnode-b827ebb40450.sonyc_relevance_2hr.h5\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    feats_dir = '/beegfs/work/sonyc/features/openl3/2017/'\n",
    "    indices_dir = '/beegfs/work/sonyc/indices/2017/'\n",
    "    output_dir = '/beegfs/sk7898/sonyc/relevance/2017'\n",
    "    \n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    get_relevance_scores_files(feats_dir, indices_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369526, 20)\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('/beegfs/sk7898/sonyc/relevance/2017/sonycnode-b827ebb40450.sonyc_relevance_2hr.h5')\n",
    "print(f['recording_index']['relevance_2hr_vector'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
